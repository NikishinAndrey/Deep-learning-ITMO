{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "В качестве лабораторной работы по теме \"Ансамбли моделей\" предлагается участие в [соревановании на Kaggle](https://www.kaggle.com/competitions/ensembles-competition/leaderboard).\n",
        "\n",
        "Основные тезисы и правила\n",
        "\n",
        "\n",
        "\n",
        "1.   В этом семестре обязательным требованием является размещение результатов выполнения лабораторных работ (всех, начиная с текущей) в своем репозитории на github. Формат — блокнот .ipynb, содержащий программный код и необходимые пояснения markdown.\n",
        "2.   Топ-3 команды, которые рассказывали о своей работе, получают автоматически 5 по этой лабе (при выполнении пункта 1. можно общий блокнот, если он один на всех, но в своем репозитории с кратким описанием своего вклада в общую работу).\n",
        "3. Остальные участники размещают также свои материалы у себя в репозитории. В случае командной работы тоже описать свой вклад (конкретно вы, что делали в рамках проекта).\n",
        "4. Без защиты можно автоматически получить оценку 3. Для более высокой оценки необходимо защитить свою работу. Защита в виде беседы, где вы опять же расскажате о том, как добились результата и о своем вкладе в случае командной работы.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uWZhVFS2I-Vm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Подгрузка исходных данных\n",
        "!gdown 1Jk3kcdU8VZwJsrcyTsbr9GLj4uSJhST4\n",
        "!unzip ensembles-competition.zip"
      ],
      "metadata": {
        "id": "xJq9ttHrsIg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q catboost\n",
        "!pip install -q lightgbm\n",
        "!pip install -q xgboost\n",
        "!pip install -q mlxtend\n",
        "!pip install -q dask[dataframe]\n",
        "!pip install optuna\n",
        "!pip install LightGBM"
      ],
      "metadata": {
        "id": "yLlbeVO9sK8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import ast\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import re\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "import numpy as np\n",
        "from catboost import CatBoostRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import optuna"
      ],
      "metadata": {
        "id": "Tw6mmmTlsMpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pd.read_csv('train_contest.csv')\n",
        "X_test = pd.read_csv('for_prediction.csv')\n",
        "y_train = X_train['mean_salary']\n",
        "X_train = X_train.drop(columns=['mean_salary'])"
      ],
      "metadata": {
        "id": "HwPxV9fdsOoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Подготовка данных"
      ],
      "metadata": {
        "id": "-eJHaSV9u6k_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dataframe_convert_bool_to_int(dataframe):\n",
        "    bool_columns = dataframe.select_dtypes(include=['bool']).columns\n",
        "    for col in bool_columns:\n",
        "        dataframe[col] = dataframe[col].astype(int)\n",
        "\n",
        "    return dataframe\n",
        "\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"<.*?>\", \"\", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    text = re.sub(r\"\\d+\", \"\", text)\n",
        "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "def combine_dict_values(x, key):\n",
        "    if pd.isna(x) or x == '[]':\n",
        "        return None\n",
        "    try:\n",
        "        dict_list = ast.literal_eval(x)\n",
        "        return ','.join([d[key] for d in dict_list])\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "\n",
        "def convert_to_lowercase(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
        "    text_columns = dataframe.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "    for column in text_columns:\n",
        "        dataframe[column] = dataframe[column].apply(lambda x: x.lower() if isinstance(x, str) else x)\n",
        "\n",
        "    return dataframe"
      ],
      "metadata": {
        "id": "79BnGLfvuUfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_vector_embeddings(dataframe: pd.DataFrame):\n",
        "    text_columns = dataframe.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "    for column in text_columns[:]:\n",
        "        print(column)\n",
        "        dataframe[column+'_embedding'] = dataframe[column].apply(lambda x: model.encode(x))\n",
        "    print('embeddings added')\n",
        "    return dataframe"
      ],
      "metadata": {
        "id": "9M_HqX5tugpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(salary):\n",
        "    # Удаление не нужных признаков\n",
        "    columns_to_drop_null = [\"response_url\", \"sort_point_distance\", \"insider_interview\", \"relations\", \"working_days\", \"working_time_intervals\", \"working_time_modes\", \"department\", 'address'] # address, department и area - вопрос как лучше с ними или без\n",
        "    columns_to_drop_unused = [\"alternate_url\", \"url\", \"immediate_redirect_url\", \"contacts\", \"published_at\", \"created_at\"]\n",
        "    salary = salary.drop(columns=columns_to_drop_null+columns_to_drop_unused)\n",
        "    salary = dataframe_convert_bool_to_int(salary)\n",
        "\n",
        "    # Достаем из json формата данные\n",
        "    salary['area'] = salary['area'].apply(\n",
        "        lambda x: None if pd.isna(x) else ast.literal_eval(x)['id']\n",
        "    )\n",
        "    salary['type'] = salary['type'].apply(\n",
        "        lambda x: None if pd.isna(x) else ast.literal_eval(x)['id']\n",
        "    )\n",
        "\n",
        "    salary['employer'] = salary['employer'].apply(\n",
        "        lambda x: None if pd.isna(x) else ast.literal_eval(x)['name']\n",
        "    )\n",
        "    salary['schedule'] = salary['schedule'].apply(\n",
        "        lambda x: None if pd.isna(x) else ast.literal_eval(x)['id']\n",
        "    )\n",
        "    salary['experience'] = salary['experience'].apply(\n",
        "        lambda x: None if pd.isna(x) else ast.literal_eval(x)['name']\n",
        "    )\n",
        "\n",
        "    salary['key_skills'] = salary['key_skills'].apply(combine_dict_values, key='name')\n",
        "    salary['specialization_name'] = salary['specializations'].apply(combine_dict_values, key='name')\n",
        "    salary['specialization_profarea_name'] = salary['specializations'].apply(combine_dict_values, key='profarea_name')\n",
        "    salary['snippet'] = salary['snippet'].apply(\n",
        "        lambda x: None if pd.isna(x) else ast.literal_eval(x)['requirement']\n",
        "    )\n",
        "    salary.drop(columns=['specializations'], inplace=True)\n",
        "\n",
        "    salary[\"description\"] = salary[\"description\"].apply(preprocess_text)\n",
        "    salary.fillna('empty', inplace=True)\n",
        "\n",
        "    salary = convert_to_lowercase(salary)\n",
        "    if labels_to_drop is not None:\n",
        "        salary = salary.drop(columns=labels_to_drop)\n",
        "        salary = pd.get_dummies(salary)\n",
        "    return salary"
      ],
      "metadata": {
        "id": "3dp_LbDkuXdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optuna"
      ],
      "metadata": {
        "id": "T3JbZXJwu80-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_prep = preprocess_data(X_train)"
      ],
      "metadata": {
        "id": "UmWo5T_cvUwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(X_train_prep)\n",
        "y = y_train.copy()"
      ],
      "metadata": {
        "id": "xaWCRF7PvC8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
        "    param = {\n",
        "        'metric': 'mae',\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 2000),\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-4, 10.0,log=True),\n",
        "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-4, 10.0,log=True),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.3, 1.0),\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.2,log=True),\n",
        "        'max_depth': trial.suggest_int('max_depth', 4, 200),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 40, 500),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 1, 500),\n",
        "        'cat_smooth': trial.suggest_int('cat_smooth', 1, 300),\n",
        "        'force_col_wise':True\n",
        "    }\n",
        "\n",
        "    model = LGBMRegressor(**param, n_jobs=-1, verbosity=-1)\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    mae = mean_absolute_error(y_test, preds)\n",
        "    return mae"
      ],
      "metadata": {
        "id": "FFp8BF69vFhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=300)"
      ],
      "metadata": {
        "id": "LR0PkCLfvKT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param = study.best_params\n",
        "model = LGBMRegressor(**param)\n",
        "model.fit(np.array(X), y)\n",
        "\n",
        "y_pred_optuna = model.predict(np.array(X_test_prep))"
      ],
      "metadata": {
        "id": "oEs-8RCgvLkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Подготовка предсказания"
      ],
      "metadata": {
        "id": "r2kGe-KevNsI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
        "\n",
        "X_test_prep = preprocess_data(X_test)\n",
        "\n",
        "missing_cols = set(X_train_prep.columns) - set(X_test_prep.columns)\n",
        "for col in missing_cols:\n",
        "    X_test_prep[col] = 0\n",
        "\n",
        "X_test_prep = X_test_prep[X_train_prep.columns]"
      ],
      "metadata": {
        "id": "KREA_Ch-vRL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pred_to_csv(y_pred, name_file):\n",
        "    df_result = pd.DataFrame(data={\"Predicted\":list(y_pred)})\n",
        "    df_result = df_result.reset_index()\n",
        "    df_result = df_result.rename(columns={\"index\":\"Id\"})\n",
        "    df_result.to_csv(f\"{name_file}.csv\", index=False)"
      ],
      "metadata": {
        "id": "UGEPLD2SvXb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_to_csv(y_pred_optuna, \"submit.csv\")"
      ],
      "metadata": {
        "id": "zCBbRrImvZuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Выводы:"
      ],
      "metadata": {
        "id": "ZFXh1oKqvenM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Наше решение:** предобработка признаков, признаки в эмбединги + обучение модели LGBMRegressor с подбором параметров с помощью Optuna\n",
        "2. **Наша команда:** Андрей, Женя, Гоша, Марат. Андрей, Женя - подготовка, отбор и очистка фич, Марат - формирование эмбедингов, тестирование альтернативных подходов, Гоша - тестирование и сравнение различных моделей + настройка Optuna.\n",
        "3. **В итоге:** 4 место, немного не хватило до 3."
      ],
      "metadata": {
        "id": "AmnQmCJjvgaT"
      }
    }
  ]
}